\chapter{Einleitung}
\pdfcomment{Herleitung Aufgabe/Chor-Geschichten}Seit einiger Zeit wird an der Hochschule Karlsruhe die Projektidee eines künstlichen Chors verfolgt, dessen Ziel darin besteht, eine Audiospur simultan in mehreren Tonhöhen wiederzugeben, um einen mehrstimmigen Chor zu erzeugen. Das zugrundeliegende technische Prinzip lässt sich recht leicht erläutern: die originale Tonspur wird mittels FFT in den Frequenzbereich transformiert, wo das Signal in die gewünschte Tonhöhe bzw. Frequenzbereich verschoben wird. Anschließend werden die Signale zurück in den Zeitbereich transformiert und abgespielt. Allerdings gestaltet sich die Umsetzung weitaus anspruchsvoller als das theoretische Konzept. Beispielsweise führen Aussetzer im WLA-Netzwerk, Puffergrößen der Audiotreiber und diskrete Stützstellen des Frequenzspektrums zu unerwarteten Problemen, die sich in Form von knackenden Lautsprechern Gehör verschaffen. Nichtsdestotrotz hat der Entwicklungsprozess den Punkt erreicht, an dem der Chor noch kaum unerwünschte Töne von sich gibt, weshalb nun die erste große Erweiterung angestrebt wird. Aktuell setzt sich das System aus einem Master-PC und vier BeagleBones zusammen, die jeweils mit einem Lautsprecher ausgestattet in einem Raum verteilt werden. Auf dem Master wird eine Tonspur eingespielt, die er in die gewünschten Tonhöhen pitcht und per WLAN an die BeagleBones sendet, welche jeweils eine der Stimmen über den Lautsprecher wiedergeben.

\pdfcomment{Ziel von fahrendem Roboter}Im nächsten Schritt soll der Chor mobilisiert werden. Das heißt jedes BeagleBone plus Lautsprecher wird auf einem Roboter montiert, die bei einer Vorführung einen beliebigen Raum betreten können und diesen auf der Suche nach einem passenden Podium erkunden. Wurde Letzteres gefunden, so sollen sich die Roboter dort im Halbkreis formieren und anschließend vorsingen.

Die neue Aufgabe, die sich mit der autonomen Navigation der Roboter beschäftigt, kann vollkommen entkoppelt von dem Chor betrachtet und bearbeitet werden. Dieser zweite Entwicklungsstrang befindet sich allerdings noch im Anfangsstadium, da sich bisher nur ein einzelnes Entwicklungsprojekt dem Thema gewidmet hat. In dieser Arbeit wurde ein erster Grundstein gelegt, der sich einerseits aus der Auswahl und Inbetriebnahme der Roboter, andererseits aus einem ersten Proof-of-Concept in Sachen Navigation zusammensetzt.

\pdfcomment{Turtlebot als Hardware}Als mobile Plattform für die Lautsprecher fiel die Wahl auf den Turtlebot 2, der von Willow Garage entwickelt wurde. Der Roboter setzt sich aus der Kobuki-Basis, einem Rechner und einer ASUS-Xtion-Pro-Live zusammen, wobei Letztere sowohl Kamera als auch Tiefensensor zur Verfügung stellt. Der Turtlebot 2 bringt als Vorteil mit sich, dass der Roboter weite Anwendung im Bereich von Hobby- und Forschungsanwendungen findet, weshalb eine breite Community-Untersützung zur Verfügung steht. Ein in dieser Arbeit wichtiges Beispiel stellt die Simulation des Roboters mithilfe von gazebo dar: Hier besteht bereits eine vollständige Integration des Turtlebot 2, die open-source zugänglich ist. Im Rahmen der Vorgängerarbeit wurde der roboter zusätzlich mit dem Laserscanner Tim551 der Marke SICK ausgestattet, der als primärer Sensor für die Navigation verwendet wird.

\pdfcomment{Robot-Operating-System}Die Programmierung erfolgt mithilfe des sogenannten Robot-Operating-System (ROS), wobei es sich ironischerweise um kein Betriebssystem sondern eine Middleware handelt, die eine Vielzahl von Tools und Paketen für die autonome Navigation bereitstellt. Dadurch müssen die Algorithmen für die Navigation und Kartographierung nicht eigenständig implementiert werden, sondern können in Form von ROS-Paketen eingesetzt werden, sodass sich die Inbetriebnahme auf die Parametrisierung der ROS-Funktionen beschränkt. Außerdem beinhaltet ROS ein Netzwerk, über das die Roboter kommunizieren können. Mithilfe der Kommunikationskanäle können auch externe Werkzeuge auf relevanten Daten zugreifen, womit komfortable und effiziente Debugging-Wege geschaffen werden. Umgekehrt können zu Beginn die Roboter auch aus dem Netz entfernt und durch ein Simulationstool wie gazebo ersetzt werden. So können die Algorithmen zunächst anhand einer Simulation erprobt und konfiguriert werden und im Anschluss unverändert auf die Roboter übertragen werden.

\pdfcomment{Erste Navigation mittels Navigation-Stack}Die im Vorgängerprojekt erarbeitete Navigationslösung basiert auf dem ROS-Navigation-Stack und setzt sich aus zwei Teilen zusammen. Im ersten Schritt wird mit dem ROS-Paket \lstinline{hector_slam}{} eine Karte der Umgebung aufgezeichnet. Anschließend navigieren die Roboter anhand der Karte zu dem vorgegebenen Ziel, wobei das ROS-Paket \lstinline{move_base}{} zum Einsatz kommt. Bei dessen Konfiguration wurden zwei verschiedene Ansätze verfolgt: Bei dem Ersten erfolgt die Lokalisierung des Roboters ausschließlich anhand der Odometriedaten. Der zweite Ansatz greift auf die AMC-Lokalisierung zurück. Der Vorteil der zweiten Variante liegt darin, dass die Ausgangsposition des Roboters nicht bekannt sein muss. Bei der Navigation mittels Odometrie übertragen sich sämtliche Fehle bei der Angabe der Anfangsposition unmittelbar auf die Navigation. Im Gegensatz dazu verspricht die AMCL-Variante - zumindest theoretisch - ein höheres Maß an Robustheit. Allerdings konnte diese Hoffnugn in den Experimenten nicht bestätigt werden, weshalb letzten Endes die Odometrie-Navigation verwendet wurde. Zusätzlich sei angemerkt, dass diese Lösung nicht im Stande ist, Hindernisse, die nicht auf der Karte verzeichnet sind, während der Navigation zu erkennen, geschweige denn, denen auszuweichen.

\pdfcomment{Funktionale Anforderungen}An dieser Stelle knüpft die vorliegende Arbeit an: Die Navigation soll an den Punkt gebracht werden, wo die Roboter im Stande sind, sich selbst auf der Karte zu lokalisieren, unerwartete Hindernisse zu detektieren und diesen entsprechend auszuweichen. Hierfür soll auf bestehende Möglichkeiten des ROS-Navigation-Stack zurückgegriffen werden, um die Menge von Lösungsmöglichkeiten einzuschränken. Auch die Anforderung, dass die Navigation auf eine mit \lstinline{hector_slam}{} aufgezeichnete Karte zurückgreifen kann, wird übernommen. Im ersten Schritt wird lediglich ein einzelner Roboter betrachtet. Sobald dieser die Anforderungen im Bereich der autonomen Navigation erfüllt, werden die Ergebnisse auf eine Gruppe von vier Robotern übertragen.

\pdfcomment{Anforderungen an die Vorgehensweise, neue Formulierung mehr als nötig}Neben den rein funktionalen Zielen legt diese Arbeit einen besonderen Wert auf die dabei verwendete Vorgehensweise. Die Arbeit beginnt bei den Grundlagen. Der Navigation-Stack soll in seine funktionalen Einheiten zerlegt werden, deren Funktionsprinzipien im Detail erläutert werden sollen. Mithilfe der so gewonnen Erkenntnisse sollen die Komponenten konfiguriert und wieder zusammengesetzt werden. Die Arbeit erhebt den Anspruch nicht nur eine Lösung zu erzielen, die die Anforderungen erfüllt, sondern auch zu kläre, weshalb die Anforderung erfüllt werden konnten. Mit der Simulation können die Teilprobleme nicht nur entkoppelt betrachtet werden, sondern auch gezielt untersucht und illustriert werden. Es sollen aussagekräftige Anwendungssituationen konstruiert werden, die die Funktionsprinzipien der Algorithmen entweder in der Simulation oder Realität aufzeigen.

\pdfcomment{Aufbau der folgendne Arbeit, das muss noch erarbeitet werden, zumindest die Struktur bzw. Abfolge der Algorithmen }